1.在现有的基础上加入词性还原
2.使用由大量文本优化过的模型
Word2Vec 提供了加载任何由 Google 原始 C 工具输出的预训练模型的函数，因此也可以在 C 中训练模型，然后将其导入 Python。
3.调节现有参数，增加模型的训练时间，目前20分种的训练时间可以再加长
4.在符号方面做更多处理，而不是简单的删除
5.使用其他的最新算法结构去测试模型，比如分布式词向量技术。如果word2vec框架达不到足够的精度（95以上），那么就要考虑更换模型
6.针对报告：
您可以创建自己的训练、验证和测试分割，并使用它们来测试您的解决方案，而不是访问比赛的测试数据集
对于您选择的挑战，您应该报告训练错误、验证错误、超参数调整，以及与竞赛中相关方法的比较
源代码没有验证集，只有训练集和测试集，所以要切割一下，可以拿unlabelled部分的数据73开，然后把测试数据集里面的一部分拿来做测试，因为是无监督的
但是如果要是做有监督和无监督的混合的话，词袋等有些方法是要做有监督的，因此也可以完全不用无监督的数据，只拿有监督的数据进行划分，本身有25000的数据样子
其实也还可以

因为涉及到比较，因此他默认的词袋法，还有word2vec的基础模型，肯定是要写入报告中的，作为比较
7.
你可能会问：为什么词袋更好？
最大的原因是，在我们的教程中，平均向量和使用质心失去了单词的顺序，使其非常类似于 Bag of Words 的概念。

8.准确率测试：每个ID后面跟着一个数字。IMDB 评分 < 5 的情绪评分为 0，评分 >=7 的情绪评分为 1
因此可以直接使用函数来简单判断准确率，不需要上传，这个是任务

9.做可视化和词云分析，可以看kaggle里面的代码评论，找比较好的方法。
训练集和验证集的准确度，损失函数曲线