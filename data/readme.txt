1.在现有的基础上加入词性还原 完成

2.使用由大量文本优化过的模型
Word2Vec 提供了加载任何由 Google 原始 C 工具输出的预训练模型的函数，因此也可以在 C 中训练模型，然后将其导入 Python。

3.调节现有参数，增加模型的训练时间，目前20分种的训练时间可以再加长

4.在符号方面做更多处理，而不是简单的删除

5.使用其他的最新算法结构去测试模型，比如分布式词向量技术。如果word2vec框架达不到足够的精度（95以上），那么就要考虑更换模型

6.针对报告：数据集分割 622 完成
您可以创建自己的训练、验证和测试分割，并使用它们来测试您的解决方案，而不是访问比赛的测试数据集
对于您选择的挑战，您应该报告训练错误、验证错误、超参数调整，以及与竞赛中相关方法的比较
源代码没有验证集，只有训练集和测试集，所以要切割一下，可以拿unlabelled部分的数据73开，然后把测试数据集里面的一部分拿来做测试，因为是无监督的
但是如果要是做有监督和无监督的混合的话，词袋等有些方法是要做有监督的，因此也可以完全不用无监督的数据，只拿有监督的数据进行划分，本身有25000的数据样子
其实也还可以
因为涉及到比较，因此他默认的词袋法，还有word2vec的基础模型，肯定是要写入报告中的，作为比较

7.
你可能会问：为什么词袋更好？
最大的原因是，在我们的教程中，平均向量和使用质心失去了单词的顺序，使其非常类似于 Bag of Words 的概念。

8.准确率测试：每个ID后面跟着一个数字。IMDB 评分 < 5 的情绪评分为 0，评分 >=7 的情绪评分为 1
因此可以直接使用函数来简单判断准确率，不需要上传，这个是任务 完成

9.做可视化和词云分析，可以看kaggle里面的代码评论，找比较好的方法。 完成
训练集和验证集的准确度，损失函数曲线
词云，以及K-means的聚类词云图片

10.如果是使用随机森林，是不方便获得测试集的，因为不好绘制图片。得考虑使用其他神经网络框架结构

它基于 NBSVM(朴素贝叶斯SVM）、段落向量和门控循环神经网络的集成


word2vec主要针对与单词，而doc2vec主要针对于文本：
dec2vec是wordvec的衍生，它主要用于对句子的分类上，word2vec将词语分类后，给每个句子创建一个id，通过id和词语进行进一步的训练，将句子分类，从而达到分句的效果。

Negative Sampling（负采样）
Word Embedding三种方法
n-gram 与 TF-IDF

Prediction based Embedding(word2vec)和gloVe(Global Vector)全局词频统计

glove 步骤
1根据语料库构建一个共现矩阵矩阵中的每一个元素Xij代表单词i和
上下文单词j在特定大小的上下文窗口（context window）内共同出现的次数。
2构建词向量和共现矩阵的关系
3构造损失函数
4训练（看似无监督训练，其实在训练的过程中提供了共现矩阵中的值，这些值是通过训练集的样本计算而来的。

最终解决方法对比，拿基础的word2vec作为竞赛方法。
而doc2vec和glove作为主力算法，最后根据具体的准确度来判断选哪个，另外两个作为对比

目标准确度 95左右吧